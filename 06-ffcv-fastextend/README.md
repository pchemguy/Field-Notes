# Building and Installation of FFCV on Windows

The [Fast Forward Computer Vision (FFCV) library](https://github.com/libffcv/ffcv) aims to address the data loading bottleneck occurring, for example, when training AI models using a large dataset not fitting within RAM and consisting of large number of small files, such as [ImageNet-1K, ILSVRC2012](https://image-net.org/challenges/LSVRC/2012/). A related project, [Fastxtend](https://github.com/warner-benjamin/fastxtend/), aims to bridge FFCV with [fastai](https://github.com/fastai/fastai). Both FFCV and fastxtend have not been unfortunately updated since 2023, but I wanted to give them a try anyway. I primarily use Windows and both projects claimed Windows support. However, FFCV proved to be quite tricky to get installed.

FFCV's GitHub repository README provides very concise installation instructions, and the initial attempts has unsurprisingly failed. Very first attempts resulted in an error with the trace referring to missing OpenCV package or something. That was the only issue covered by the provided installation instructions.

The next troubleshooting round was due to a confusing message regarding missing Microsoft Visual C++. It was confusing for a couple reasons. On the one hand, I had not anticipated that this package would require compilation (in fact, besides GitHub, FFCV is primarily distributed as a PyPI package, and its [download section](https://pypi.org/project/ffcv/#files) clearly shows that only source code distribution is available). And a major issue, however, was in fact that I installed [MS Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools), a native Windows toolchain, which I used before (though I used a separate installation) for direct building (not involving Python). I have previously discussed a Micromamba-based [approach](https://github.com/pchemguy/Field-Notes/blob/main/03-python-env-windows/README.md) to bootstrapping clean Python environments, which does not have a Python dependency. Being able to reproducibly and efficiently bootstrap clean Python environments without the need to use base/system/root Python installation is particularly important for troubleshooting environment configuration problems. While this message may indicate what is say - MS Build Tools not actually being installed, this issues has been covered in various sources, e.g., this [SO answer](https://stackoverflow.com/a/64262038/17472988). I have also covered the causes of Python (actually `pip`/`setuptools`) not seeing activated MSBuild environment in an [SO QA](https://stackoverflow.com/q/79789580) and a [separate post](https://github.com/pchemguy/Field-Notes/blob/main/05-python-pip-msvc/README.md), so I will not cover these issues here.

The third round of troubleshooting yielded an error, which was coming from linker and was characteristic of missing build dependencies - the linker was unable to locate the necessary libraries to resolve certain calls. When managing build dependencies within the Python-pip-setuptools-MSVC Build Tools environment, it is important to realize that some of these dependencies may be available and installed as PyPI/Conda package. Further, some of such packages, in fact, provide only Python bindings without including the files required by the build process, some provide "reduced" library versions which may not provide all the necessary functionality, some provide alternative builds that may or may not be fully compatible (or be outright incompatible) with the project being build, yet others are perfectly fine and can be used without obtaining a separate installation.

While in the ideal world `pip install` would hide all the complex details of the building process, in real world it is not always the case. Whether `pip install` build process would succeed actually to a large extent depends on the authors of the package being built - aspect to large extent beyond the control of `pip`.  The author of the package being built are responsible for creating a setup script that supplies the necessary information to `setuptools` to be used for constructing compiler and linker command lines. In particular, there are three key pieces about dynamic loaded library dependencies that must be provided to the build toolchain for it to successfully resolve external dependencies, with the fourth item being runtime requirement:
1. location of `*.h` header files (typically found within the include directory) for the compiler
2. location of `*.lib` import library files for the linker
3. importantly, specific names of import library files to be used by the linker (compiler uses `#include` directives to identify required header files, but linker does not have a similar guiding about `*.lib` files)
4. location of dll files (this location needs to be on the path, but it is not actually used by the toolchain during the building process; it is required, however, by the built package for it to be able to start and function).
The last position - the location of DLLs - is a runtime requirement, this location must be added to the Path variable (within environment activation script - do not pollute the system Path!) and must be set by the user. Correctly setting the first three positions is essential for the building process to succeed. In theory, the setup script of the package being built must provide the first three items to `setuptools` correctly for it to build compiler/linker commands. The error message from the linker may mean that there is an issue with setup instructions (either on part of their preparation by the author or on part of user following them, or both, including potential paths/names collision) and/or that there is an issue with information provided by the setup script to `setuptools`. In practice, because Linux has a standardized location for installed `*.h` and `*.lib` files, setting configuring dependencies when building on Linux usually requires a simpler associated setup script logic. Windows, on the other hand, does not have a dedicated standard location for `*.h` and `*.lib` files. While avoiding system-wide installation of dependencies, which is more natural on Windows due to lack of a standard location is advantageous for creating isolated tailored environments, lack of standard location complicates the build setup logic, as the setup script must somehow figure this information if attempting to perform automatic configuration without user intervention. Now, names of required `*.lib` files are determined by the library regardless of its actual location and this part should be, generally, less of a problem for the setup script (though there might be some case-by-case nuances).

As far as isolated Python environments are concerned, ideally there could be established a convention for placing dependencies within a dedicated directory either under the environment directory or placing dependencies and the environment directory under the same parent directory. In fact, modern Python environments have a dedicated `Library` directory with `Library/bin`, `Library/include`, and `Library/lib` subdirectories to be used as a shared environment location for library files included in packages. For example, Conda packages `pthreads` and `libjpeg-turbo` include entire libraries (both runtime DLLs and developer/ build-time `*.h` and `*.lib`) and conda/mamba installers place files included in these packages in respective shared directories. `pip install` command is executed in the context of environment as well, so it knows location of the top directory (containing `python.exe`)
